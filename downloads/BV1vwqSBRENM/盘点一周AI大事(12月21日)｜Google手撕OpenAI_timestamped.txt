[00:00.000 -> 00:02.000] 一分鐘看完一周AI大事
[00:02.000 -> 00:04.400] OpenAI上線最強圖像模型
[00:04.400 -> 00:06.520] 主打精準編輯和文字渲染
[00:06.520 -> 00:09.320] 世界知識和多語言能力略輸小香蕉
[00:09.320 -> 00:11.640] OpenAI發布最強編碼模型
[00:11.640 -> 00:13.519] 能工程化交付大型代碼庫
[00:13.519 -> 00:16.640] 智能體從編程助手變成基礎設施
[00:16.640 -> 00:18.440] Google發布Gemini 3 Flash
[00:18.440 -> 00:21.199] 智商僅次於自家大哥和GPT 5.2
[00:21.199 -> 00:22.359] 速度快三倍
[00:22.359 -> 00:23.719] 價格只要四分之一
[00:23.719 -> 00:25.000] 用極致性價比
[00:25.000 -> 00:26.800] 搶占OpenAI的市場份額
[00:26.800 -> 00:28.760] Google開源A2UI協議
[00:28.800 -> 00:30.320] 告別純文字聊天限制
[00:30.320 -> 00:32.079] AI能及時生成UI介面
[00:32.079 -> 00:33.439] 讓用戶直接操作
[00:33.439 -> 00:36.000] Gemini深度研究上線可視化報告
[00:36.000 -> 00:38.120] 能從訴諸生成複雜的圖表
[00:38.120 -> 00:40.000] 微軟開源最強3D模型
[00:40.000 -> 00:42.200] 能直接導出3D建模文件
[00:42.200 -> 00:43.640] 使用全新方法表徵
[00:43.640 -> 00:45.439] 拓樸結構和貼圖細節
[00:45.439 -> 00:47.400] 質量吊打所有3D模型
[00:47.400 -> 00:49.680] 阿里開源分層編輯圖像模型
[00:49.680 -> 00:52.120] 能把圖片拆成語意結偶的多圖層
[00:52.120 -> 00:54.520] 像PS一樣單獨修改特定元素
[00:54.520 -> 00:56.400] 阿里發布VO3平T
[00:56.439 -> 00:58.920] 主打原聲音化同步和多鏡頭敘事
[00:58.920 -> 01:00.119] 自帶客串功能
[01:00.119 -> 01:02.199] 你也能捏一個AI明星出道
[01:02.199 -> 01:03.879] 字節發布VO3平T
[01:03.879 -> 01:05.120] 原聲音品輸出
[01:05.120 -> 01:07.000] 支持多語言和各種方言
[01:07.000 -> 01:08.680] 還能根據動作生成音效
[01:08.680 -> 01:10.079] 支持電影及運鏡
[01:10.079 -> 01:11.480] 演員及情緒表達
[01:11.480 -> 01:13.840] AI做視頻進化成AI拍電影
[01:13.840 -> 01:16.359] 騰訊開源首個實時交互視界模型
[01:16.359 -> 01:17.319] 而私幀速率
[01:17.319 -> 01:18.920] 實時渲染無限視界
[01:18.920 -> 01:20.759] 支持第一視角和第三視角
[01:20.759 -> 01:22.640] 能用來錄視頻製作遊戲
[01:22.640 -> 01:24.239] 可零上限運動控制
[01:24.239 -> 01:25.960] 能完美復刻任意動作
[01:26.000 -> 01:27.879] 製譜開源最強動作復刻模型
[01:27.879 -> 01:30.239] 能提取3D姿態再渲染視頻
[01:30.239 -> 01:32.759] 解決了2D姿態容易穿幫的問題
[01:32.759 -> 01:35.280] 研究員開源3D立體視頻模型
[01:35.280 -> 01:37.839] 能把普通視頻轉成3D電影
[01:37.839 -> 01:39.679] Adobe開源P視頻模型
[01:39.679 -> 01:42.319] 能直接改變對象的光照材質和紋理
[01:42.319 -> 01:44.479] 改一幀就能應用整個視頻
[01:44.479 -> 01:46.879] 英偉達開源長視頻生成模型
[01:46.879 -> 01:49.239] 能生成5分鐘長視頻不退化
[01:49.239 -> 01:51.359] 研究員開源視頻超速模型
[01:51.359 -> 01:54.839] 多個加速框架聯手生成速度提升200倍
[01:54.840 -> 01:56.880] 研究員開源照片重新對焦
[01:56.880 -> 01:58.799] 能把拍攝壺的對象變清楚
[01:58.799 -> 02:00.880] 也能反過來做背景虛化
[02:00.880 -> 02:02.960] 研究員開源實時換臉模型
[02:02.960 -> 02:04.680] 12G顯存可運行
[02:04.680 -> 02:06.359] 阿里開源TTS模型
[02:06.359 -> 02:08.120] 不需要樣本就能克隆音色
[02:08.120 -> 02:09.840] 還能邊輸入邊發聲
[02:09.840 -> 02:12.640] 跟換臉結合就能做虛擬偶像直播
[02:12.640 -> 02:15.000] Meta開源最強聲音分割模型
[02:15.000 -> 02:18.159] 能從任意音頻分離指定的聲音或組合
[02:18.159 -> 02:20.680] AI2開源最強視頻理解模型
[02:20.680 -> 02:22.560] Mistral發布最強OCR模型
[02:22.599 -> 02:25.879] Stepfun開源最強手機行動智能體
[02:25.879 -> 02:29.479] 馬斯克稱2026年Grook會率先達成AGI
[02:29.479 -> 02:31.479] 去年他預告的是2025年